{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import kfp\n",
    "from kfp import dsl\n",
    "from kfp.v2.compiler import Compiler\n",
    "from kfp.client import Client\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import pickle\n",
    "\n",
    "# Define the data preparation component using @dsl.component\n",
    "@dsl.component\n",
    "def data_prep_op() -> str:\n",
    "    # Load MNIST dataset\n",
    "    (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "    # Normalize and reshape data\n",
    "    x_train = x_train.astype(\"float32\") / 255.0\n",
    "    x_test = x_test.astype(\"float32\") / 255.0\n",
    "    x_train = x_train[..., tf.newaxis]\n",
    "    x_test = x_test[..., tf.newaxis]\n",
    "\n",
    "    # Save preprocessed data to a file\n",
    "    data_path = \"/mnt/data/mnist_data.pkl\"\n",
    "    os.makedirs(os.path.dirname(data_path), exist_ok=True)\n",
    "    with open(data_path, \"wb\") as f:\n",
    "        pickle.dump((x_train, y_train, x_test, y_test), f)\n",
    "\n",
    "    print(f\"Data saved to {data_path}\")\n",
    "    return data_path\n",
    "\n",
    "\n",
    "# Define the model training component using @dsl.component\n",
    "@dsl.component\n",
    "def train_model_op(data_path: str) -> str:\n",
    "    # Load preprocessed data\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        x_train, y_train, _, _ = pickle.load(f)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_train = tf.keras.utils.to_categorical(y_train, 10)\n",
    "\n",
    "    # Build and train the model\n",
    "    model = models.Sequential([\n",
    "        layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(28, 28, 1)),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"softmax\")\n",
    "    ])\n",
    "\n",
    "    model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
    "    model.fit(x_train, y_train, epochs=5, batch_size=64, validation_split=0.2)\n",
    "\n",
    "    # Save the model\n",
    "    model_path = \"/mnt/data/mnist_model.h5\"\n",
    "    os.makedirs(os.path.dirname(model_path), exist_ok=True)\n",
    "    model.save(model_path)\n",
    "    print(f\"Model saved to {model_path}\")\n",
    "    return model_path\n",
    "\n",
    "\n",
    "# Define the model evaluation component using @dsl.component\n",
    "@dsl.component\n",
    "def evaluate_model_op(model_path: str, data_path: str) -> float:\n",
    "    # Load the model and test data\n",
    "    model = tf.keras.models.load_model(model_path)\n",
    "    with open(data_path, \"rb\") as f:\n",
    "        _, _, x_test, y_test = pickle.load(f)\n",
    "\n",
    "    # Convert labels to one-hot encoding\n",
    "    y_test = tf.keras.utils.to_categorical(y_test, 10)\n",
    "\n",
    "    # Evaluate the model\n",
    "    test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "    print(f\"Test Accuracy: {test_acc}\")\n",
    "    return test_acc\n",
    "\n",
    "\n",
    "# Define the pipeline using the @dsl.pipeline decorator\n",
    "@dsl.pipeline(\n",
    "    name=\"demo2\",\n",
    "    description=\"A pipeline to train and evaluate an Demo 2 MNIST model.\"\n",
    ")\n",
    "def mnist_pipeline():\n",
    "    # Data preparation step\n",
    "    data_prep_task = data_prep_op()\n",
    "\n",
    "    # Model training step\n",
    "    train_model_task = train_model_op(data_path=data_prep_task.output)\n",
    "\n",
    "    # Model evaluation step\n",
    "    evaluate_model_op(model_path=train_model_task.output, data_path=data_prep_task.output)\n",
    "\n",
    "\n",
    "# Compile the pipeline and upload it to Kubeflow\n",
    "PIPELINE_NAME = \"demo2\"\n",
    "PIPELINE_FILE = f\"{PIPELINE_NAME}.yaml\"\n",
    "\n",
    "# Compile the pipeline to a YAML file\n",
    "Compiler().compile(pipeline_func=mnist_pipeline, package_path=PIPELINE_FILE)\n",
    "print(f\"Pipeline compiled to {PIPELINE_FILE}\")\n",
    "\n",
    "# Connect to the Kubeflow client\n",
    "client = Client(namespace=\"kubeflow\")\n",
    "\n",
    "# Upload the pipeline to Kubeflow\n",
    "pipeline = client.upload_pipeline(pipeline_package_path=PIPELINE_FILE, pipeline_name=PIPELINE_NAME)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
